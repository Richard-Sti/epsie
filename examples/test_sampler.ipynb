{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of creating and running a sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will setup a sampler to sample a 2D Gaussian distribution with mean $\\bar{x} = 2, \\bar{y} = 5$ and variance $\\sigma_x^2 = 1$, $\\sigma_y^2 = 2$; $\\sigma^2_{xy} = \\sigma^2_{yx} = 0$, using a prior that is uniform over $x, y \\in [-20, 20)$.\n",
    "\n",
    "We will use Python's multiprocessing to evolve 12 chains using 4 cores. We will then make an animation showing how the 12 chains moved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from __future__ import print_function\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "import randomgen\n",
    "\n",
    "import epsie\n",
    "from epsie.sampler import Sampler\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model to sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** Below we create a class with several functions to draw samples from the prior and to evaluate the log posterior. This isn't strictly necessary. The only thing the Sampler really requires is a function that it can pass keyword arguments to and get back a tuple of (log likelihood, log prior). However, setting things up as a class will make it convenient to, e.g., draw random samples from the prior for the starting positiions, as well as plot the model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "class Model(object):\n",
    "    def __init__(self):\n",
    "        # we'll use a 2D Gaussian for the likelihood distribution\n",
    "        self.params = ['x', 'y']\n",
    "        self.mean = [2., 5.]\n",
    "        self.cov = [[1., 0.], [0., 2.]]\n",
    "        self.likelihood_dist = stats.multivariate_normal(mean=self.mean,\n",
    "                                                         cov=self.cov)\n",
    "\n",
    "        # we'll just use a uniform prior\n",
    "        self.prior_bounds = {'x': (-20., 20.),\n",
    "                             'y': (-20., 20.)}\n",
    "        xmin = self.prior_bounds['x'][0]\n",
    "        dx = self.prior_bounds['x'][1] - xmin\n",
    "        ymin = self.prior_bounds['y'][0]\n",
    "        dy = self.prior_bounds['y'][1] - ymin\n",
    "        self.prior_dist = {'x': stats.uniform(xmin, dx),\n",
    "                           'y': stats.uniform(ymin, dy)}\n",
    "\n",
    "    def prior_rvs(self, size=None):\n",
    "        return {p: self.prior_dist[p].rvs(size=size)\n",
    "                for p in self.params}\n",
    "    \n",
    "    def logprior(self, **kwargs):\n",
    "        return sum([self.prior_dist[p].logpdf(kwargs[p]) for p in self.params])\n",
    "    \n",
    "    def loglikelihood(self, **kwargs):\n",
    "        return self.likelihood_dist.logpdf([kwargs[p] for p in self.params])\n",
    "    \n",
    "    def __call__(self, **kwargs):\n",
    "        logp = self.logprior(**kwargs)\n",
    "        if logp == -numpy.inf:\n",
    "            logl = None\n",
    "        else:\n",
    "            logl = self.loglikelihood(**kwargs)\n",
    "        return logl, logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and run the sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pool of 4 parallel processes, then initialize the sampler using the model we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nchains = 12\n",
    "nprocs = 4\n",
    "pool = multiprocessing.Pool(nprocs)\n",
    "\n",
    "sampler = Sampler(model.params, model, nchains, pool=pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now set the starting positions of the chains by drawing random variates from the model's prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.set_start(model.prior_rvs(size=nchains))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's run it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will evolve each chain in the collection by 250 steps. This is parallelized over the pool of processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.run(250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the history of all of the chains using the `.positions` attribute. This will return a dictionary mapping parameter names (in this case, `'x'` and `'y'`) to numpy arrays with shape `nchains x niterations`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampler.positions: <type 'dict'> with keys/values:\n",
      "\"x\": <type 'numpy.ndarray'> with shape (12, 250)\n",
      "\"y\": <type 'numpy.ndarray'> with shape (12, 250)\n"
     ]
    }
   ],
   "source": [
    "positions = sampler.positions\n",
    "print('sampler.positions: {} with keys/values:'.format(type(positions)))\n",
    "for param in sorted(positions):\n",
    "    print('\"{}\": {} with shape {}'.format(param, type(positions[param]), positions[param].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access the history of log likelihoods and log priors using `sampler.stats`, as well as the acceptance ratios that were found at each point with `sampler.acceptance_ratios`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampler.stats: <type 'dict'> with keys/values:\n",
      "\"logl\": <type 'numpy.ndarray'> with shape (12, 250)\n",
      "\"logp\": <type 'numpy.ndarray'> with shape (12, 250)\n"
     ]
    }
   ],
   "source": [
    "stats = sampler.stats\n",
    "print('sampler.stats: {} with keys/values:'.format(type(stats)))\n",
    "for stat in sorted(stats):\n",
    "    print('\"{}\": {} with shape {}'.format(stat, type(stats[stat]), stats[stat].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampler.acceptance ratios: <type 'numpy.ndarray'> with shape (12, 250)\n"
     ]
    }
   ],
   "source": [
    "acceptance_ratios = sampler.acceptance_ratios\n",
    "print('sampler.acceptance ratios: {} with shape {}'.format(type(acceptance_ratios), acceptance_ratios.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model returned \"blobs\" (i.e., the model returns a dictionary along with the logl and logp), then we can also access those using `sampler.blobs`. Similar to `positions`, this would also be a dictionary of arrays with keys given by the names in the dictionary the model returned. However, because our model above returns no blobs, in this case we just get `None`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(sampler.blobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The individual chains can be accessed using the `.chains` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<epsie.chain.Chain at 0x11fb53290>,\n",
       " <epsie.chain.Chain at 0x10f86ae10>,\n",
       " <epsie.chain.Chain at 0x11fb6c4d0>,\n",
       " <epsie.chain.Chain at 0x11fb53dd0>,\n",
       " <epsie.chain.Chain at 0x11fb6cad0>,\n",
       " <epsie.chain.Chain at 0x11fb70150>,\n",
       " <epsie.chain.Chain at 0x11fb70810>,\n",
       " <epsie.chain.Chain at 0x11fb70f50>,\n",
       " <epsie.chain.Chain at 0x11fb86650>,\n",
       " <epsie.chain.Chain at 0x11fb86e90>,\n",
       " <epsie.chain.Chain at 0x11fb90b90>,\n",
       " <epsie.chain.Chain at 0x11fb90490>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler.chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an animation of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the results, we'll create an animation showing how the chains evolved. We'll do this by plotting one point for each chain, with each frame in the animation representing a single iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note: To keep file size down, the animation has not been created for the version of this notebook uploaded to the repository.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare an array to create a density map showing the shape of the model posterior\n",
    "npts = 100\n",
    "xmean, ymean = model.likelihood_dist.mean\n",
    "xsig = model.likelihood_dist.cov[0,0]**0.5\n",
    "ysig = model.likelihood_dist.cov[1,1]**0.5\n",
    "X, Y = numpy.mgrid[xmean-3*xsig:xmean+3*xsig:complex(0, npts),\n",
    "                   ymean-3*ysig:ymean+3*ysig:complex(0, npts)]\n",
    "Z = numpy.zeros(X.shape)\n",
    "for ii in range(Z.shape[0]):\n",
    "    for jj in range(Z.shape[1]):\n",
    "        logl, logp = model(x=X[ii,jj], y=Y[ii,jj])\n",
    "        Z[ii, jj] = numpy.exp(logl+logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pyplot.subplots()\n",
    "\n",
    "positions = sampler.positions\n",
    "xdata = positions['x']\n",
    "ydata = positions['y']\n",
    "\n",
    "# Plot contours showing the shape of the true posterior density\n",
    "#ax.contour(X, Y, Z, 2, colors='k', linewidths=1, linestyles='dashed', zorder=-2)\n",
    "ax.imshow(numpy.rot90(Z), extent=[X.min(), X.max(), Y.min(), Y.max()],\n",
    "          aspect='auto', cmap='binary', zorder=-3)\n",
    "\n",
    "# Put an x at the maximum posterior point\n",
    "ax.scatter(model.mean[0], model.mean[1], marker='x', color='w', s=10, zorder=-2)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "# create the scatter points\n",
    "ptsize = 60\n",
    "\n",
    "# we'll include the last bufferlen number of steps a chain visited, having the size and transparency\n",
    "# exponentially damped with each new frame\n",
    "bufferlen = 16\n",
    "alphas = numpy.exp(-4*(numpy.arange(bufferlen))/float(bufferlen))\n",
    "sizes = ptsize * alphas\n",
    "#colors = numpy.array(['C{}'.format(ii) for ii in range(nchains)])\n",
    "colors = numpy.arange(nchains)\n",
    "plts = [ax.scatter(xdata[:, bufferlen-ii-1], ydata[:, bufferlen-ii-1], c=colors, s=sizes[ii],\n",
    "                   edgecolors='w', linewidths=0.5,\n",
    "                   alpha=alphas[ii], zorder=bufferlen-ii, marker='s' if ii==0 else 'o', cmap='jet')\n",
    "        for ii in range(bufferlen)]\n",
    "# put a + showing the average of the chain positions at the current iteration\n",
    "meanplt = ax.scatter(xdata[:,0].mean(), ydata[:,0].mean(), marker='P', c='w', edgecolors='k', linewidths=0.5,\n",
    "                     zorder=bufferlen+1)\n",
    "\n",
    "# add some text giving the iteration\n",
    "itertxt = 'Iteration {}'\n",
    "txt = ax.annotate(itertxt.format(1), (0.03, 0.94), xycoords='axes fraction')\n",
    "\n",
    "def animate(ii):\n",
    "    txt.set_text(itertxt.format(ii+1))\n",
    "    for jj,plt in enumerate(plts):\n",
    "        plt.set_offsets(numpy.array([xdata[:, max(ii-jj, 0)], ydata[:, max(ii-jj, 0)]]).T)\n",
    "    meanplt.set_offsets([xdata[:,ii].mean(), ydata[:,ii].mean()])\n",
    "    # zoom in as it narrows on the result\n",
    "    istart = max(ii-bufferlen, 0)\n",
    "    # smooth it out a bit\n",
    "    xmin = numpy.array([xdata[:, max(istart-kk, 0):].min() for kk in range(50)]).mean()\n",
    "    xmax = numpy.array([xdata[:, max(istart-kk, 0):].max() for kk in range(50)]).mean()\n",
    "    ymin = numpy.array([ydata[:, max(istart-kk, 0):].min() for kk in range(50)]).mean()\n",
    "    ymax = numpy.array([ydata[:, max(istart-kk, 0):].max() for kk in range(50)]).mean()\n",
    "    ax.set_xlim((1.1 if xmin < 1 else 0.9)*xmin, (0.9 if xmax < 1 else 1.1)*xmax)\n",
    "    ax.set_ylim((1.1 if ymin < 1 else 0.9)*ymin, (0.9 if ymax < 1 else 1.1)*ymax)\n",
    "\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, frames=xdata.shape[1], interval=160, blit=True)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the animation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save('chain_animation.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
